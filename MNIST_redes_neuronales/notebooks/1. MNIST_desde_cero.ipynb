{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Sergio Andres Rios Gomez</h3>\n",
    "<h4> EA4. MNIST desde cero </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import struct\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Funciones para leer los archivos .ubyte:</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\", f.read(16))\n",
    "        images = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "        images = images.reshape(num, rows * cols)\n",
    "        return images / 255.0  # Normalizar\n",
    "\n",
    "def load_labels(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        magic, num = struct.unpack(\">II\", f.read(8))\n",
    "        labels = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "        return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../data/raw/\"\n",
    "X_train = load_images(DATA_PATH + \"train-images.idx3-ubyte\")\n",
    "y_train = load_labels(DATA_PATH + \"train-labels.idx1-ubyte\")\n",
    "X_test = load_images(DATA_PATH + \"t10k-images.idx3-ubyte\")\n",
    "y_test = load_labels(DATA_PATH + \"t10k-labels.idx1-ubyte\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> One-hot encoding de etiquetas </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(labels, num_classes=10):\n",
    "    return np.eye(num_classes)[labels]\n",
    "\n",
    "y_train_oh = one_hot_encode(y_train)\n",
    "y_test_oh = one_hot_encode(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Inicializar red neuronal. Red simple:</p>\n",
    "<li> Capa de entrada: 784 (28x28)</li>\n",
    "<li> Capa oculta: 64 </li>\n",
    "<li> Capa de salida: 10 (dígitos) </li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(input_size, hidden_size, output_size):\n",
    "    np.random.seed(42)\n",
    "    W1 = np.random.randn(input_size, hidden_size) * 0.01\n",
    "    b1 = np.zeros((1, hidden_size))\n",
    "    W2 = np.random.randn(hidden_size, output_size) * 0.01\n",
    "    b2 = np.zeros((1, output_size))\n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Funciones de activación y pérdida </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "def softmax(x):\n",
    "    exps = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "    return exps / np.sum(exps, axis=1, keepdims=True)\n",
    "\n",
    "def cross_entropy(y_pred, y_true):\n",
    "    m = y_pred.shape[0]\n",
    "    log_likelihood = -np.log(y_pred[range(m), y_true.argmax(axis=1)])\n",
    "    return np.sum(log_likelihood) / m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Forward y backward propagation </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(X, W1, b1, W2, b2):\n",
    "    Z1 = np.dot(X, W1) + b1\n",
    "    A1 = sigmoid(Z1)\n",
    "    Z2 = np.dot(A1, W2) + b2\n",
    "    A2 = softmax(Z2)\n",
    "    return Z1, A1, Z2, A2\n",
    "\n",
    "def backward(X, y, Z1, A1, A2, W2):\n",
    "    m = X.shape[0]\n",
    "    dZ2 = A2 - y\n",
    "    dW2 = np.dot(A1.T, dZ2) / m\n",
    "    db2 = np.sum(dZ2, axis=0, keepdims=True) / m\n",
    "\n",
    "    dA1 = np.dot(dZ2, W2.T)\n",
    "    dZ1 = dA1 * sigmoid_derivative(Z1)\n",
    "    dW1 = np.dot(X.T, dZ1) / m\n",
    "    db1 = np.sum(dZ1, axis=0, keepdims=True) / m\n",
    "\n",
    "    return dW1, db1, dW2, db2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Entrenamiento </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y, X_val, y_val, epochs=10, lr=0.1, hidden_size=64):\n",
    "    input_size = X.shape[1]\n",
    "    output_size = y.shape[1]\n",
    "\n",
    "    W1, b1, W2, b2 = init_params(input_size, hidden_size, output_size)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        Z1, A1, Z2, A2 = forward(X, W1, b1, W2, b2)\n",
    "        loss = cross_entropy(A2, y)\n",
    "\n",
    "        dW1, db1, dW2, db2 = backward(X, y, Z1, A1, A2, W2)\n",
    "\n",
    "        W1 -= lr * dW1\n",
    "        b1 -= lr * db1\n",
    "        W2 -= lr * dW2\n",
    "        b2 -= lr * db2\n",
    "\n",
    "        if (epoch + 1) % 1 == 0:\n",
    "            _, _, _, A2_test = forward(X_val, W1, b1, W2, b2)\n",
    "            acc = np.mean(np.argmax(A2_test, axis=1) == np.argmax(y_val, axis=1))\n",
    "            print(f\"Epoch {epoch+1}, Loss: {loss:.4f}, Accuracy: {acc:.4f}\")\n",
    "\n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Evaluación </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(X, y, W1, b1, W2, b2):\n",
    "    _, _, _, A2 = forward(X, W1, b1, W2, b2)\n",
    "    pred_labels = np.argmax(A2, axis=1)\n",
    "    true_labels = np.argmax(y, axis=1)\n",
    "    accuracy = np.mean(pred_labels == true_labels)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Entrenamiento y pruebas</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.3016, Accuracy: 0.1135\n",
      "Epoch 2, Loss: 2.3006, Accuracy: 0.1135\n",
      "Epoch 3, Loss: 2.3002, Accuracy: 0.1135\n",
      "Epoch 4, Loss: 2.2997, Accuracy: 0.1135\n",
      "Epoch 5, Loss: 2.2993, Accuracy: 0.1135\n",
      "Epoch 6, Loss: 2.2988, Accuracy: 0.1135\n",
      "Epoch 7, Loss: 2.2983, Accuracy: 0.1135\n",
      "Epoch 8, Loss: 2.2978, Accuracy: 0.1135\n",
      "Epoch 9, Loss: 2.2972, Accuracy: 0.1135\n",
      "Epoch 10, Loss: 2.2965, Accuracy: 0.1135\n",
      "Epoch 11, Loss: 2.2959, Accuracy: 0.1135\n",
      "Epoch 12, Loss: 2.2951, Accuracy: 0.1135\n",
      "Epoch 13, Loss: 2.2943, Accuracy: 0.1135\n",
      "Epoch 14, Loss: 2.2934, Accuracy: 0.1135\n",
      "Epoch 15, Loss: 2.2924, Accuracy: 0.1135\n",
      "Epoch 16, Loss: 2.2912, Accuracy: 0.1135\n",
      "Epoch 17, Loss: 2.2900, Accuracy: 0.1135\n",
      "Epoch 18, Loss: 2.2886, Accuracy: 0.1135\n",
      "Epoch 19, Loss: 2.2870, Accuracy: 0.1135\n",
      "Epoch 20, Loss: 2.2853, Accuracy: 0.1138\n",
      "Test accuracy: 0.1138\n"
     ]
    }
   ],
   "source": [
    "W1, b1, W2, b2 = train(X_train, y_train_oh, X_test, y_test_oh, epochs=20, lr=0.5, hidden_size=64)\n",
    "\n",
    "test_acc = evaluate(X_test, y_test_oh, W1, b1, W2, b2)\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Conclusiones</h3>\n",
    "<li> Una epoch es una pasada completa por todos los datos de entrenamiento. </li>\n",
    "<li>El loss o pérdida es un número que indica qué tan mal lo está haciendo el modelo. Un valor alto indica que el modelo se está equivocando mucho.</li>\n",
    "<li>La accuracy es el porcentaje de predicciones correctas.</li>\n",
    "<h3> ¿Qué hicimos en este proyecto?</h3>\n",
    "<li>Cargar manualmente los datos del MNIST en formato .ubyte</li>\n",
    "<li>Preprocesar los datos (aplanarlos, normalizarlos, codificar etiquetas).</li>\n",
    "<li>Implementar una red neuronal básica de 2 capas, usando. Propagación hacia adelante, Funciones de activación, One-hot encoding, Cálculo de pérdida y accuracy</li>\n",
    "<li>Entrenar la red por varias epochs</li>\n",
    "<li>Evaluar el rendimiento del modelo en el conjunto de prueba</li>\n",
    "<h3> ¿Por qué es importante hacer esto manualmente? </h3>\n",
    "<li>Comprensión profunda. Entender cómo fluye la información en una red neuronal.</li>\n",
    "<li>Valor como profesional. Diferencia alguien que entiende la teoría y la práctica.</li>\n",
    "<li>Desarrollo de habilidades sólidas. Mejora la lógica, pensamiento algorítmico y habilidad con vectores y matrices.</li>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
